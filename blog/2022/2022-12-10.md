# 2022-12-10 - SSH/BBS logo gen fun

had a holiday last week and woke up to wondering how sometimes you still see banners on telnet/ssh connections, in good old BBS vein, so wondered how much effort it'd be to grab a company's logo and just convert it into something semi-decent in the terminal and all of this with as little effort as possible.

i came up with this :

```shell
curl -s $SVG_FILE_URI | convert -background none -compress none -density 1200 -scale $(tput cols)x$(tput lines) - -monochrome PGM:- | sed -e 1,3d | perl -ne 'foreach(split(/\s/)){print($_?"*":" ")}print"\n"'
```

the original one grabbed the company URL, used `xmllint` with

* `--html` to be more forgiving of the crappy html
* `--xpath "string(//*[@class='brand']/img/@data-lazy-src)"` to grab the required chunk of data
* `-` to process stdin and
* `2 >/dev/null` to redirect all the annoying warnings on STDERR that i couldn't get rid of with any xmllint args

my thought process was to grab the image, convert it to 'some simple image format like ppm' and then just grab the pixel data converting it to asterisks with 'some lang'.

looking into ppm i found the amazing pgm format, which was exactly what i needed and more. it's a grayscale format, so i'd not even have to bother with the rgba values, just check if the value's a zero and move on if not. with a bit of fiddling with `convert` (the gazillions of args sometimes take a bit to re-master, guess those of you that know IM will concur) i came up with the args :

* `-background none` to get full transparency
* `-compress none` to get the 'plain text' subformat of PGM
* `-density 1200` this for some reason helped with the SVG conversion
* `-scale $(tput cols)x$(tput lines)` to scale it to the terminal size; so here i'd like to add that i ended up using 'tput' so that i could also add this snippet into a script (the original one used ${COLUMNS}x${LINES} but as you know that's only available directly in the shell, it's not exported.
* `-` to use STDIN for the input
* `-monochrome` to convert to 8bit output
* `PGM:-` to provide the PGM format as output and the STDOUT as target fd for the output

this worked well without the `-monochrome` arg, although after checking it on another machine i had to insert it between the IN and OUT paths, to work also on that machine.

since PGM has a header and i didn't want to bother parsing that too, just skipped it with `sed`.

the rest is just the perl command with shortcuts :

* read STDIN
* iterate STDIN by splitting the lines by 'whitespace'
* convert each string into either '*' or ' '
* the end result looks as you'd expect from such a small effort, but i got what i wanted so i was happy.

...happy until i got the itch of wanting to get rid of `convert`, because while curl, xmllint, perl you will probably find on modern boxes, but IM you may not... so i had another idea :

why don't i look for another way to convert the image, perhaps piggybacking some regular command in the shell that i've not used before, so started looking into this...

my idea was to either use some tool i'm not aware is around on macos (the box i use for work) or i dunno, maybe processing the png/svg/other some way. as a simpleton i'll oft ram my head into impossible things, but it keeps me entertained at least.

so i started looking around and found a bunch of useless or deprecated, removed, etc tools or ones that were simply not for the cause (`cupsfilter` for instance, that i saw someone suggest on SO).

after some wasted time and my cause not moving forward i figured rather than trying to woo safari into cooperation using applescript (that i somehow never got to nor like nor master), i'd give chromium headless a go.

chromium headless is something i merely heared of before, back when they introduced it in some beta release and i remember test automation devs feeling all positive about it.

what i wanted was to give it some input and get some output, but had no idea how exactly i'd do this, so went to the doc, which lists the options of :

* print the DOM
* convert to PDF
* take a screenshot
* use the REPL
* use a third party lib (puppeteer) to 'make it move'
* use another third party lower level lib (cri)
* connect to it remotely using another chromium instance
* probably a ton of other third party ways...

so anyway, i don't like third party, in fact my goal here is to use LESS third parties, so my only choices as far as i could tell were :

* take a screenshot which will prolly be PNG and then i'll have to somehow crack that open to retrieve the pixel data
* convert my input into a string and output a PDF, then use `strings` to extract it
* use the REPL and somehow print the pixel data as a string

so PNG isn't as simple as i'd hope of course and it might turn out to be a bigger effort reading the pixels after decompression (even if it's prolly predetermined, so i'd not have to support multiple ways, should any exist), so after a bit of hexdumping i decided to move on

the PDF idea wasn't going too well either, somehow the page was always empty, plus i had to keep opening the PDF for viewing, rather than seeing the result immediately, which slowed me down as well.

the REPL idea was getting me somewhere at least, but there my pain was that it only understands single lines, so storing the js code that i wanted to feed chromium was making me turn it into a string of oneliners, since there's no way to tell the REPL that the command continues on the next line (like you'd do with backslash on any shell).

but i was out of options pretty much and i kept trying and trying with the REPL, but it wasn't getting me anywhere.

then i thought... maybe i could use the DOM...? i dunno... something stupid, like a div with a bunch of rgba values..? so i moved on to the next chapter - trying to work with the DOM.

my thought process here was :

* get the image (prolly pass some args to disable cors)
* grab the pixels
* create a div with the text content being a string of space separated rgba values

as you more experienced people will know, one does not simply extract pixels in js, though the added bit wasn't all that much work, updating my list of steps to :

* get the image
* draw the image onto a canvas
* grab the pixels
* write them to a div

i had some issues with cors, as well as `canvas tainted by cross origin data` but i will bore you no longer with the details. long story short, the final workflow is the following :

* wrap the whole lot in a try catch block, so i can debug it easily if it fails (no console available when fiddling with headless)
* instantiate Image
* set .onload to
    * draw image on canvas
    * get canvas data and for each pixel append the rgba values as hex string to a string buffer
    * rewrite `document` with the stringbuf data
* set .crossOrigin = "anonymous"
* set .src to the URL

finally the only issue i had was how to pass the URL to the index.html file that i'd feed headless, but i decided to use the simplest solution here too, just went with `location.hash` (fragment part of the URI).

for kicks, i also spent some time converting the `index.html` page to a datauri to feed that to headless and that works too, so the end result was pretty much the same, though of course worse, due to my crappy conversion implementation compared to majestic `convert`'s.